__author__ = "Homa Papoli Yazdi"
__email__ = "homa.papoli_yazdi@biol.lu.se"

#--------------------------------------------------------------------------------------------------------------------------------------------------#
configfile: "config/config.yaml"
localrules: all, edit_assemblies, multiqc, multiqc_after_filtering, multiqc_after_filtering_bbtools, create_intervals, create_gdb_mapfile, create_sorted_vcf_list, get_dist_plots
genome_name=config["genome"]
#--------------------------------------------------------------------------------------------------------------------------------------------------#

#--------------------------------------------------------------------------------------------------------------------------------------------------#
#--------------------Import Python modules---------------------------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------------------------------------#
import pandas as pd
import os
import matplotlib.pyplot as plt
#--------------------------------------------------------------------------------------------------------------------------------------------------#
#--------------------Reading design table----------------------------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------------------------------------#
design_table = pd.read_table(config["sample_table"], sep="\t")
sample_name = design_table.Sample_Name
fastq_name = design_table.Fastq_Name
ploidy_level = design_table.Ploidy
fastq_names_with_ploidy_2 = ",".join(design_table[(design_table['Ploidy'] == 2) & (~design_table['Sample_Name'].str.startswith('GLA'))]['Fastq_Name'].tolist())
fastq_names_with_ploidy_4 = ",".join(design_table[design_table['Ploidy'] == 4]['Fastq_Name'].tolist())
fastq_names_with_ploidy_6 = ",".join(design_table[design_table['Ploidy'] == 6]['Fastq_Name'].tolist())
#--------------------Function to get Read Group for each sample------------------------------------------------------------------------------------#
def get_readgroup(sample_name):
    read_group = pd.read_table("config/ReadGroup.txt", sep="\t")
    read_group_dict = dict(read_group.values)
    return read_group_dict[sample_name]
#--------------------------------------------------------------------------------------------------------------------------------------------------#
#------------------Function to get Ploidy level for each sample------------------------------------------------------------------------------------#
def get_ploidy(sample_name):
    design_table = pd.read_table(config["sample_table"], sep="\t")
    ploidy_dict = dict(zip(design_table.Fastq_Name, design_table.Ploidy))
    return ploidy_dict[sample_name]
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule all:
    input: 
        html_output = expand([
        "data/genome/{genome}.fasta",
        "results/fastqc/{sample}_{pair}_001_fastqc.html",
        "results/multiqc/multiqc_report.html",
        "data/fastq_filtered/{sample}_R1_001.filtered.fastq.gz",
        "data/fastq_filtered/{sample}_R2_001.filtered.fastq.gz",
        "results/fastp_report/{sample}.html",
        "results/fastqc_filtered/{sample}_{pair}_001.filtered_fastqc.html",
        "results/fastqc_filtered/{sample}_{pair}_001.filtered_fastqc.zip",
        "results/multiqc_filtered/multiqc_report.html",
        "data/genome/{genome}.fasta.amb",
        "data/genome/{genome}.fasta.ann",
        "data/genome/{genome}.fasta.bwt",
        "data/genome/{genome}.fasta.pac",
        "data/genome/{genome}.fasta.sa",
        "data/genome/{genome}.dict",
        "data/genome/{genome}.fasta.fai",
        "results/mapped/{sample}.sorted.bai",
        "results/mapped/{sample}.flagstats.txt",
        "results/mapped/{sample}.idxstat.txt",
        "results/mapped_dedup/{sample}.dedup.bam",
        "results/mapped_dedup/{sample}.metrics.txt",
        "config/intervals/interval_{num}.bed",
        "results/gvcf/{sample}/{sample}.{num}.gvcf",
        "config/sample_map/interval_{num}.sample_map",
        "results/genomicsdb/interval_{num}_gdb",
        "results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_{num}.vcf",
        "results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_{num}_sorted.vcf",
        "results/cat_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted.vcf.gz",
        "results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz",
        "results/filtered_vcf/depth_diploid.txt",
        "results/filtered_vcf/depth_tetraploid.txt",
        "results/filtered_vcf/depth_hexaploid.txt",
        "results/filtered_vcf/info_field.txt",
        "config/total_mapped_reads.txt",
        "results/filtered_vcf/info_plots_grid.pdf",
        "results/filtered_vcf/diploid_tetra_hexa_ratio.pdf",
        "results/filtered_vcf/summary_statistics_with_ploidy.csv",
        "results/filtered_vcf/summary_statistics_depth_allVCF.csv",
        "results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic_gatkHardFilter.vcf.gz",
        "results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic_gatkHardFilter_passed.vcf.gz",
        "results/filtered_vcf/passed_snp_count.txt",
        "results/filtered_vcf/info_field_passed.txt"
        ], sample=fastq_name, pair=config["pair"], genome=config["species"], num=range(1, 48))
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule edit_assemblies:
    input:
        genome = os.path.join("data/genome", (genome_name+".fasta"))
    output:
        edited_genome = "data/genome/{genome}.fasta",
        genome_stats = "data/genome/{genome}.stats.txt"
    params:
        species = "Lbolanderi"
    shell:
        """
        python workflow/scripts/assembly_stats.py {params.species} {input.genome} {output.edited_genome} {output.genome_stats}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule fastqc:
    input:
       fastq="data/fastq/{sample}_{pair}_001.fastq.gz",
    output:
        fastqc_html="results/fastqc/{sample}_{pair}_001_fastqc.html",
        fastqc_zip="results/fastqc/{sample}_{pair}_001_fastqc.zip"
    params:
        outdir="results/fastqc"
    resources:
        threads = 1,
        runtime = "3h"
    singularity:
        "containers/fastqc_0.12.1.sif"
    shell:
        """
        fastqc {input} \
        --outdir {params.outdir} \
        --kmers 7 
        """

# rule multiqc:
#     input:
#         expand("results/fastqc/{sample}_{pair}_001_fastqc.zip", sample=fastq_name, pair=config["pair"])
#     output:
#         "results/multiqc/multiqc_report.html"
#     singularity:
#         "containers/multiqc_v1.25.sif"
#     shell:
#         "multiqc results/fastqc/*fastqc.zip -o results/multiqc"

rule filtering_fastp:
    input:
        fastq1="data/fastq/{sample}_R1_001.fastq.gz",
        fastq2="data/fastq/{sample}_R2_001.fastq.gz"
    output:
        fastq1_filtered="data/fastq_filtered/{sample}_R1_001.filtered.fastq.gz",
        fastq2_filtered="data/fastq_filtered/{sample}_R2_001.filtered.fastq.gz",
        unpaired1="data/fastq_unpaired/{sample}_unpaired1.fastq.gz",
        unpaired2="data/fastq_unpaired/{sample}_unpaired2.fastq.gz",
        failed_out="data/fastq_failed/{sample}.failed.fastq.gz",
        html_report="results/fastp_report/{sample}.html"
    resources:
        threads=10,
        runtime="12h"
    singularity:
        "containers/fastp_0.23.4.sif"
    shell:
        """
        fastp \
        --in1 {input.fastq1} \
        --in2 {input.fastq2} \
        --out1 {output.fastq1_filtered} \
        --out2 {output.fastq2_filtered} \
        --unpaired1 {output.unpaired1} \
        --unpaired2 {output.unpaired2} \
        --failed_out {output.failed_out} \
        --html {output.html_report} \
        --trim_poly_g 12 \
        --qualified_quality_phred=20 \
        --unqualified_percent_limit=40 \
        --length_required=140 \
        --overrepresentation_analysis \
        --adapter_sequence="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA" \
        --adapter_sequence_r2="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT" \
        --thread {resources.threads}
        """

rule fastqc_after_filtering:
    input:
       fastq="data/fastq_filtered/{sample}_{pair}_001.filtered.fastq.gz"
    output:
        fastqc_html="results/fastqc_filtered/{sample}_{pair}_001.filtered_fastqc.html",
        fastqc_zip="results/fastqc_filtered/{sample}_{pair}_001.filtered_fastqc.zip"
    params:
        outdir="results/fastqc_filtered",
        sample_adapter="data/adapters/adapters.txt"
    resources:
        threads = 1,
        runtime = "3h"
    singularity:
        "containers/fastqc_0.12.1.sif"
    shell:
        """
        fastqc {input} \
        --threads {resources.threads} \
        --outdir {params.outdir} \
        --kmers 7 \
        --adapters {params.sample_adapter}
        """

# rule multiqc_after_filtering:
#     input:
#         expand("results/fastqc_filtered/{sample}_{pair}_001.filtered_fastqc.zip", sample=fastq_name, pair=config["pair"])
#     output:
#         "results/multiqc_filtered/multiqc_report.html"
#     singularity:
#         "containers/multiqc_v1.25.sif"
#     shell:
#         "multiqc results/fastqc_filtered/*filtered_fastqc.zip -o results/multiqc_filtered"
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# Create Genome Indices
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule bwa_index:
    input:
        "data/genome/{genome}.fasta",
    output:
        idx=multiext("data/genome/{genome}.fasta", ".amb", ".ann", ".bwt", ".pac", ".sa")
    resources:
        threads= 3,
        runtime= "2h"
    singularity:
        "containers/bwa_0.7.18.sif"
    shell:
        """
        bwa index {input}
        """

rule createSeqdict:
    input:
        genome_fasta="data/genome/{genome}.fasta"
    output:
        genome_fasta_dict="data/genome/{genome}.dict"
    resources:
        threads=4,
        runtime="5h",
    singularity:
        "containers/picard_3.2.0.sif"
    shell:
        """
        java -jar /usr/picard/picard.jar CreateSequenceDictionary \
        --REFERENCE {input} \
        --OUTPUT {output}
        """

rule createSeqfai:
    input:
        genome_fasta="data/genome/{genome}.fasta"
    output:
        genome_index="data/genome/{genome}.fasta.fai"
    resources:
        threads= 4,
        runtime= "2h",
    singularity:
        "containers/samtools_1.20.c.sif"
    shell:
        """
        samtools faidx {input}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# Mapping
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule bwa_mem:
    input:
        fastq1="data/fastq_filtered/{sample}_R1_001.filtered.fastq.gz",
        fastq2="data/fastq_filtered/{sample}_R2_001.filtered.fastq.gz",
        genome_fasta="data/genome/Lbolanderi.fasta",
        amb="data/genome/Lbolanderi.fasta.amb",
        ann="data/genome/Lbolanderi.fasta.ann",
        bwt="data/genome/Lbolanderi.fasta.bwt",
        pac="data/genome/Lbolanderi.fasta.pac",
        sa="data/genome/Lbolanderi.fasta.sa"
    output:
        sam=temp("results/mapped/{sample}.sam")
    params:
        readgroup=lambda wildcards: get_readgroup(wildcards.sample)
    resources:
        threads= 18,
        runtime= "18h",
        mem_mb= 115200,
        tmpdir="$SNIC_TMP"
    benchmark:
        "benchmark/bwa_mem/{sample}.bwa_mem.txt"
    singularity:
        "containers/bwa_0.7.18.sif",
    shell:
        """
        bwa mem -M -t {resources.threads} -R {params.readgroup} {input.genome_fasta} {input.fastq1} {input.fastq2} > {output.sam}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# SAM to BAM - Sorting - Getting BAM statistics
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule samtools_sam:
    input:
        sam="results/mapped/{sample}.sam"
    output:
        bam=temp("results/mapped/{sample}.sorted.bam"),
        bai="results/mapped/{sample}.sorted.bai",
        flagstats="results/mapped/{sample}.flagstats.txt",
        idxstat="results/mapped/{sample}.idxstat.txt"
    resources:
        threads= 10,
        runtime= "10h",
        tmpdir="$SNIC_TMP"
    benchmark:
        "benchmark/samtools_sam/{sample}.samtools_sam.txt"
    singularity:
        "containers/samtools_1.20.c.sif"
    shell:
        """
        samtools flagstat {input.sam} > {output.flagstats}
        samtools sort {input.sam} -T {resources.tmpdir} -O BAM | tee {output.bam} | samtools index - {output.bai}
        samtools idxstats {output.bam} > {output.idxstat}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# Mark duplicates in BAM file
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule markduplicates_bam:
    input:
        bam="results/mapped/{sample}.sorted.bam"
    output:
        dedupBam=protected("results/mapped_dedup/{sample}.dedup.bam"),
        metrics="results/mapped_dedup/{sample}.metrics.txt"
    resources:
        threads=15,
        runtime="12h",
        mem_mb=90000,
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx90g"
    benchmark:
        "benchmark/mapped_dedup/{sample}.picardMarkDuplicates.txt"
    singularity:
        "containers/picard_3.2.0.sif"
    shell:
        """
        java {params.mem} -jar /usr/picard/picard.jar MarkDuplicates --INPUT {input} --OUTPUT {output.dedupBam} --METRICS_FILE {output.metrics} --TMP_DIR {resources.tmpdir} \
        --VALIDATION_STRINGENCY LENIENT \
        --ASSUME_SORT_ORDER coordinate \
        --CREATE_INDEX TRUE
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule create_intervals:
    input:
        genome="data/genome/Lbolanderi.fasta"
    output:
        intervals=expand("config/intervals/interval_{num}.bed", num=[i for i in range(1, 48)])
    params:
        num_scafs_per_interval = 300,
        intervals_dir="config/intervals"
    shell:
        """
        python workflow/scripts/split_fasta.py {input.genome} {params.num_scafs_per_interval} {params.intervals_dir}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule HaplotypeCaller_gvcf:
    input:
        genome_fasta="data/genome/Lbolanderi.fasta",
        genome_fasta_dict="data/genome/Lbolanderi.dict",
        genome_index="data/genome/Lbolanderi.fasta.fai",
        bam="results/mapped_dedup/{sample}.dedup.bam"
    output:
        gvcf="results/gvcf/{sample}/{sample}.{num}.gvcf"
    resources:
        threads=2,
        mem_mb=12000,
        runtime="24h",
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx12g",
        interval="config/intervals/interval_{num}.bed",
        ploidy=lambda wildcards: get_ploidy(wildcards.sample)
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options {params.mem} HaplotypeCaller \
        -R {input.genome_fasta} \
        -I {input.bam} \
        -O {output.gvcf} \
        -L {params.interval} \
        -ploidy {params.ploidy} \
        --tmp-dir {resources.tmpdir} \
        -ERC GVCF
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule create_gdb_mapfile:
    input:
        design_table=config["sample_table"]
    output:
        expand("config/sample_map/interval_{num}.sample_map", num=range(1, 48))
    run:
        design_table = pd.read_table(input.design_table, sep="\t")
        fastq_name = design_table.Fastq_Name
        for num in range(1, 48):
            sample_map = f"config/sample_map/interval_{num}.sample_map"
            with open(sample_map, "w") as sample_map_file:
                for fqname in fastq_name:
                    sample_map_file.write(f"{fqname}\tresults/gvcf/{fqname}/{fqname}.{num}.gvcf\n")
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule genomicsdbimport:
    input:
        sample_map="config/sample_map/interval_{num}.sample_map"
    output:
        db=directory("results/genomicsdb/interval_{num}_gdb")
    resources:
        threads=1,
        mem_mb=6400,
        runtime="48h",
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx6g",
        interval="config/intervals/interval_{num}.bed",
        sample_map="config/sample_map/interval_{num}.sample_map"
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options {params.mem} GenomicsDBImport \
        --genomicsdb-workspace-path {output.db} \
        --intervals {params.interval} \
        --batch-size 50 \
        --sample-name-map {params.sample_map} \
        --tmp-dir {resources.tmpdir} 
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule GenotypeGVCFs:
    input:
        db="results/genomicsdb/interval_{num}_gdb",
        genome_fasta="data/genome/Lbolanderi.fasta"
    output:
        vcf="results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_{num}.vcf"
    resources:
        threads=4,
        mem_mb=24000,
        runtime="48h",
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx24g",
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options {params.mem} GenotypeGVCFs \
        -R {input.genome_fasta} \
        -V gendb://{input.db} \
        -O {output.vcf} \
        --tmp-dir {resources.tmpdir}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule SortVCFs:
    input:
        vcf="results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_{num}.vcf"
    output:
        vcf_sorted="results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_{num}_sorted.vcf"
    resources:
        threads=4,
        mem_mb=24000,
        runtime="48h",
        tmpdir="$SNIC_TMP"
    params:
        genome_fasta_dict="data/genome/Lbolanderi.dict",
        mem= "-Xmx24g",
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options {params.mem} SortVcf -I {input.vcf} -O {output.vcf_sorted} -SD {params.genome_fasta_dict} --TMP_DIR {resources.tmpdir}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# Create a list for concatenate_VCF
rule create_sorted_vcf_list:
    output:
        sorted_vcf_list="config/vcf_list/sorted_vcf.list"
    shell:
        """
        for i in {{1..47}}
        do 
        echo results/vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_${{i}}_sorted.vcf >> {output.sorted_vcf_list}
        done
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule concatenate_VCF:
    input:
        vcf_list="config/vcf_list/sorted_vcf.list"
    output:
        concat_vcf="results/cat_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted.vcf.gz"
    resources:
        threads=2,
        runtime="12h",
        mem_mb=12000,
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx12g"
    singularity:
        "containers/picard_3.2.0.sif"
    shell:
        """
        java {params.mem} -jar /usr/picard/picard.jar MergeVcfs \
        --INPUT {input.vcf_list} \
        --OUTPUT {output.concat_vcf}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule keep_biallelic_SNPs:
    input:
        concat_vcf="results/cat_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted.vcf.gz"
    output:
        snp_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz"
    resources:
        threads=2,
        runtime="12h",
        mem_mb=12000,
        tmpdir="$SNIC_TMP"
    singularity:
        "containers/bcftools_1.21.sif"
    shell:
        """
        bcftools view -m2 -M2 -v snps {input.concat_vcf} --output-type z --output {output.snp_vcf}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule index_vcf:
    input:
        vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz"
    output:
        index="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz.tbi"
    resources:
        threads=4,
        mem_mb=24000,
        runtime="48h",
        tmpdir="$SNIC_TMP"
    params:
        mem= "-Xmx24g",
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options {params.mem} IndexFeatureFile -I {input.vcf} 
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule get_info_field:
    input:
        biallelic_snp_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz"
    output:
        info_field="results/filtered_vcf/info_field.txt"
    resources:
        threads=1,
        runtime="12h",
        mem_mb=6000,
        tmpdir="$SNIC_TMP"
    singularity:
        "containers/bcftools_1.21.sif"
    shell:
        """
        bcftools query -f '%CHROM\\t%POS\\t%AF\\t%BaseQRankSum\\t%DP\\t%ExcessHet\\t%FS\\t%InbreedingCoeff\\t%MQ\\t%MQRankSum\\t%QD\\t%ReadPosRankSum\\t%SOR\\n' {input.biallelic_snp_vcf} > {output.info_field}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule get_depth:
    input:
        biallelic_snp_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz"
    output:
        depth_diploid="results/filtered_vcf/depth_diploid.txt",
        depth_tetraploid="results/filtered_vcf/depth_tetraploid.txt",
        depth_hexaploid="results/filtered_vcf/depth_hexaploid.txt",
        total_mapped_reads="config/total_mapped_reads.txt"
    params:
        samples_2x=fastq_names_with_ploidy_2,
        samples_4x=fastq_names_with_ploidy_4,
        samples_6x=fastq_names_with_ploidy_6
    resources:
        threads=1,
        runtime="12h",
        mem_mb=6000,
        tmpdir="$SNIC_TMP"
    singularity:
        "containers/bcftools_1.21.sif"
    shell:
        """
        bcftools query -f '%CHROM\\t%POS\\t%DP[\\t%DP]\\n' -s {params.samples_2x} {input.biallelic_snp_vcf} > {output.depth_diploid}
        bcftools query -f '%CHROM\\t%POS\\t%DP[\\t%DP]\\n' -s {params.samples_4x} {input.biallelic_snp_vcf} > {output.depth_tetraploid}
        bcftools query -f '%CHROM\\t%POS\\t%DP[\\t%DP]\\n' -s {params.samples_6x} {input.biallelic_snp_vcf} > {output.depth_hexaploid}

        sed -i 's/\\./0/g' {output.depth_diploid}
        sed -i 's/\\./0/g' {output.depth_tetraploid} 
        sed -i 's/\\./0/g' {output.depth_hexaploid}

        grep '+ 0 mapped' results/mapped/*flagstats.txt | cut -f1 -d " " | cut -f3 -d "/" | sed 's/.flagstats.txt:/ /g' | awk 'BEGIN{{print "sample","totalreads"}}{{print $0}}' > {output.total_mapped_reads}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule get_dist_plots:
    input:
        info_field="results/filtered_vcf/info_field.txt",
        depth_diploid="results/filtered_vcf/depth_diploid.txt",
        depth_tetraploid="results/filtered_vcf/depth_tetraploid.txt",
        depth_hexaploid="results/filtered_vcf/depth_hexaploid.txt"
    output:
        info_plots="results/filtered_vcf/info_plots_grid.pdf",
        depth_output="results/filtered_vcf/diploid_tetra_hexa_ratio.pdf",
        summary_depth_stats="results/filtered_vcf/summary_statistics_with_ploidy.csv",
        summary_stats_depth_allVCF="results/filtered_vcf/summary_statistics_depth_allVCF.csv"
    shell:
        """
        module load R/4.3.2
        Rscript workflow/scripts/snp_metrics_dist.R
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule gatk_variant_filter:
    # For DP filtering, I take two times the median of total depth as the maximum and half of it as the minimum (median(sampled_diploid_data$total_depth))
    input:
        vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz",
        index="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic.vcf.gz.tbi",
        reference="data/genome/Lbolanderi.fasta"
    output:
        filtered_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic_gatkHardFilter.vcf.gz"
    params:
        mem="-Xmx12g"
    resources:
        threads=2,
        mem_mb=12000,
        runtime="24h",
        tmpdir="$SNIC_TMP"
    singularity:
        "containers/gatk_4.6.0.0.sif"
    shell:
        """
        gatk --java-options "{params.mem}" VariantFiltration \
            -R {input.reference} \
            -V {input.vcf} \
            --filter-expression "QUAL < 30.0" --filter-name "VeryLowQual" \
            --filter-expression "QD < 5.0" --filter-name "LowQD" \
            --filter-expression "FS > 60.0" --filter-name "StrandBiasFishers" \
            --filter-expression "MQ < 40.0" --filter-name "MappingQuality" \
            --filter-expression "MQRankSum < -12.5" --filter-name "MQRankSum" \
            --filter-expression "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum" \
            --filter-expression "SOR > 3.0" --filter-name "SOR" \
            --filter-expression "DP < 594" --filter-name "DPtoolow" \
            --filter-expression "DP > 2376" --filter-name "DPtoohigh" \
            -O {output.filtered_vcf}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
rule filter_and_count_snps:
    input:
        filtered_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic_gatkHardFilter.vcf.gz"
    output:
        clean_vcf="results/filtered_vcf/Lbolanderi_2x.4x.6x_Lglabrum_2x_sorted_snp_biallelic_gatkHardFilter_passed.vcf.gz",
        snp_count="results/filtered_vcf/passed_snp_count.txt",
        info_field_passed="results/filtered_vcf/info_field_passed.txt"
    resources:
        threads=1,
        runtime="12h",
        mem_mb=6000,
        tmpdir="$SNIC_TMP"
    singularity:
        "containers/bcftools_1.21.sif"
    shell:
        """
        # Remove "FAIL" flagged variants and output a clean VCF
        bcftools view -f PASS {input.filtered_vcf} -o {output.clean_vcf} -O z

        # Index the clean VCF
        bcftools index {output.clean_vcf}

        # Count the remaining SNPs
        bcftools view -v snps {output.clean_vcf} | grep -vc "^#" > {output.snp_count} 

        bcftools query -f '%CHROM\\t%POS\\t%AF\\t%BaseQRankSum\\t%DP\\t%ExcessHet\\t%FS\\t%InbreedingCoeff\\t%MQ\\t%MQRankSum\\t%QD\\t%ReadPosRankSum\\t%SOR\\n' {input.filtered_vcf} > {output.info_field_passed}
        """
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# rule remove_repeats:
#     input:
    # grep -v "#" ../../data/genome/repeatmask/Struthio_camelus.20130116.OM.fa.out.gff | \
    # awk 'BEGIN{print "chrom""\t""chromStart""\t""chromEnd"}{print $1"\t"$4-1"\t"$5}' > ../../data/bed/ostrich_repeats.bed
    # bcftools view -T ^../../data/bed/ostrich_repeats.bed ${variant_VCF} -O z -o ${output_path}/${output_prefix}_vcf.filtered.repeatmasked.vcf.gz

#     output:
#     shell:
#--------------------------------------------------------------------------------------------------------------------------------------------------#
# rule all_samples_PCA:
#     input:
#     output:
#     shell:
# #--------------------------------------------------------------------------------------------------------------------------------------------------#